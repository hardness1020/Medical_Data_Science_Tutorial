<h1 align="center">Medical Data Science Tutorial</h1>

<div align="center">

</div>

## ğŸ“ Table of Contents

- [About](#about)
- [Getting Started](#getting_started)
- [Content](#content)
- [Usage](#usage)
- [Authors](#authors)
- [Acknowledgments](#acknowledgement)

</br>

## ğŸ§ About <a name = "about"></a>

### Aim

A tutorial for establishing an ensemble model to stratify patients with acute myeloid leukemia (AML) into three risk groups based on non-clinician-initiated data. 

The performance of the model is compared to the [European LeukemiaNet (ELN) risk stratification system](https://ashpublications.org/blood/article/129/4/424/36196/Diagnosis-and-management-of-AML-in-adults-2017-ELN).

### Dataset

The tabular data used in this tutorial is from the paper: [Unified classification and risk-stratification in Acute Myeloid Leukemia](https://www.nature.com/articles/s41467-022-32103-8#MOESM1).

- NCRI cohort (for training and validation)
- SG cohort (for testing, external cohort).

<!-- The tutorial is based on the paper by [Haferlach et al. (2018)](https://www.nature.com/articles/s41591-018-0026-7).  -->



</br>

## ğŸ Getting Started <a name = "getting_started"></a>

**If you don't have GPU, try using [Google Colab](https://colab.research.google.com/github/hardness1020/Medical_Data_Science_Tutorial/blob/main/tutorial.ipynb).**

### Installing (local usage)

Install the packages

```
pip3 install -r requirements.txt
```

</br>

## ğŸ”§ Content <a name = "content"></a>

The tutorial is divided into three parts:

### 1. Data Preprocessing

- Feature selection
- Data normalization

### 2. Model training

- Model selection: random forest, xgboost
- Hyperparameter optimizer: hyperopt
- Ensemble: loss-based weighting

### 3. Model evaluation

- Performance metrics: Accuracy, F1-score
- Visualization: Confusion matrix
- Survival Analysis: Kaplan-Meier estimator, C-index

</br>

## ğŸˆ Usage <a name="usage"></a>

### Folder Structure

    â”œâ”€â”€ dataset : row data
    â”‚   â”œâ”€â”€ NCRI.tsv : NCRI cohort (for training and validation)
    â”‚   â””â”€â”€ SG.tsv   : SG cohort (for testing, external cohort)
    â”‚
    â”œâ”€â”€ utils: utility functions
    â”‚   â”œâ”€â”€ hyperparameters
    â”‚   â”‚   â”œâ”€â”€ hyperoptimizer.py : hyperparameter optimizer
    â”‚   â”‚   â””â”€â”€ space.py          : hyperparameters spaces for each model
    |   â”œâ”€â”€ aml_spliter.py          : split and normalize the dataset into training, validation set 
    |   â”œâ”€â”€ get_image_bytes.py      : plot and convert confusion matrix to bytes
    |   â”œâ”€â”€ KM_survival_analysis.py : plot the survival curve and calculate the p-value
    |   â””â”€â”€ selected_features.py    : feature selected in the study
    |   
    â”œâ”€â”€ tutorial.ipynb: tutorial (not yet provided)
    |
    (The tutorial will produce the following files)
    |
    â”œâ”€â”€ data_preprocessed : preprocessed data
    â”‚   â”œâ”€â”€ NCRI.csv
    â”‚   â””â”€â”€ SG.csv
    |
    â””â”€â”€ ESB_result
        â”œâ”€â”€ best_trial : store the best parameters of each model
        â”œâ”€â”€ models     : store each model with the best parameters and weights of each model
        â””â”€â”€ prediction : store the predictions of each model
            â”œâ”€â”€ train      : store the predictions of the training set
            â”œâ”€â”€ validation : store the predictions of the validation set
            â””â”€â”€ external   : store the predictions of the test set
    
    
    

### Tutorial

Follow the step by step in **tutorial.ipynb**


</br>

## âœï¸ Authors <a name = "authors"></a>

- [@hardness1020](https://github.com/hardness1020)

</br>

## ğŸ‰ Reference <a name = "reference"></a>

